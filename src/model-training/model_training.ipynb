{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e20b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lib_ml.preprocessing import preprocess_dataset\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91045c00",
   "metadata": {},
   "source": [
    "## Transforming the data\n",
    "- We read the `.tsv` file and split the data into X and y.\n",
    "- Then we clean the data using the lib_ml library.\n",
    "- Then we transform the data and save the used CountVectorizer to upload later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867a3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/a1_RestaurantReviews_HistoricDump.tsv', delimiter = '\\t', quoting = 3)\n",
    "corpus, labels = preprocess_dataset(dataset)\n",
    "cv = CountVectorizer(max_features = 1420)\n",
    "data = cv.fit_transform(corpus).toarray()\n",
    "bow_path = '../../models/c1_BoW_Sentiment_Model.pkl'\n",
    "pickle.dump(cv, open(bow_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694cfbe",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "- Using the labels and data, the model is trained using a gridsearch over the given parameter grid with a specified number of folds.\n",
    "- The best score and best model is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a013fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_and_train(data, labels, classifier, param_grid, cv_folds):\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    scoring = 'accuracy' \n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=1,    \n",
    "        return_train_score=False,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting GridSearchCV with {cv_folds} folds...\")\n",
    "    print(f\"Parameter Grid: {param_grid}\")\n",
    "\n",
    "    grid_search.fit(data, labels)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_ \n",
    "    best_estimator = grid_search.best_estimator_ \n",
    "\n",
    "    print(\"\\n--- GridSearchCV Complete ---\")\n",
    "    print(f\"Best Parameters Found: {best_params}\")\n",
    "    print(f\"Best Cross-Validation Score ({scoring}): {best_score:.6f}\")\n",
    "    print(\"-\" * 29)\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e58ee",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "- We train different classifiers with parameter grids as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e50140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussuanNB_Classify(data, labels, cv_folds):\n",
    "    classifier = GaussianNB()\n",
    "    param_grid = {\n",
    "        'classifier__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    }\n",
    "\n",
    "    best_score, best_estimator = create_pipeline_and_train(\n",
    "        data,\n",
    "        labels,\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv_folds\n",
    "    )\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2696813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_Classify(data, labels, cv_folds):\n",
    "\n",
    "    classifier = SGDClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'classifier__loss': ['hinge', 'log', 'squared_hinge', 'perceptron'],\n",
    "        'classifier__alpha': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'classifier__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'classifier__max_iter': [1000, 2000, 3000],\n",
    "        'classifier__tol': [1e-3, 1e-4, 1e-5]\n",
    "    }\n",
    "\n",
    "    best_score, best_estimator = create_pipeline_and_train(\n",
    "        data,\n",
    "        labels,\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv_folds\n",
    "    )\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b3b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Classify(data, labels, cv_folds):\n",
    " \n",
    "    classifier = LogisticRegression(random_state=42)\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l2', 'l1'],\n",
    "        'classifier__solver': ['liblinear', 'saga'],\n",
    "        'classifier__max_iter': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    best_score, best_estimator = create_pipeline_and_train(\n",
    "        data,\n",
    "        labels,\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv_folds\n",
    "    )\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7950682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classify(data, labels, cv_folds):\n",
    "    classifier = SVC(random_state=42)\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'classifier__gamma': ['scale', 'auto'],\n",
    "        'classifier__degree': [2, 3, 4]\n",
    "    }\n",
    "\n",
    "    best_score, best_estimator = create_pipeline_and_train(\n",
    "        data,\n",
    "        labels,\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv_folds\n",
    "    )\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ce599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Classify(data, labels, cv_folds):\n",
    "\n",
    "    classifier = KNeighborsClassifier()\n",
    "    param_grid = {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'classifier__leaf_size': [10, 20, 30]\n",
    "    }\n",
    "\n",
    "    best_score, best_estimator = create_pipeline_and_train(\n",
    "        data,\n",
    "        labels,\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv_folds\n",
    "    )\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ef0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Classify(data, labels, cv_folds):\n",
    "    \n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    best_score, best_estimator = create_pipeline_and_train(\n",
    "        data,\n",
    "        labels,\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv_folds\n",
    "    )\n",
    "\n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39858632",
   "metadata": {},
   "source": [
    "## Checking the models\n",
    "- We check the outcomes of training all the models to see which obtained the best results on a fresh test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b523b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score  = 0.0\n",
    "best_estimator = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337f432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_GaussianNB(data, labels):\n",
    "    global best_score, best_estimator\n",
    "    temp_score, temp_estimator = GaussuanNB_Classify(data, labels, 5)\n",
    "    print(f\"GaussianNB best score: {temp_score}\")\n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        best_estimator = temp_estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1475d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_SGD(data, labels):\n",
    "    global best_score, best_estimator\n",
    "    temp_score, temp_estimator = SGD_Classify(data, labels, 5)\n",
    "    print(f\"SGDClassifier best score: {temp_score}\")\n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        best_estimator = temp_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6218a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Logistic(data, labels):\n",
    "    global best_score, best_estimator\n",
    "    temp_score, temp_estimator = Logistic_Classify(data, labels, 5)\n",
    "    print(f\"LogisticRegression best score: {temp_score}\")\n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        best_estimator = temp_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac46a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_SVM(data, labels):\n",
    "    global best_score, best_estimator\n",
    "    temp_score, temp_estimator = SVM_Classify(data, labels, 5)\n",
    "    print(f\"SVC best score: {temp_score}\")\n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        best_estimator = temp_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c1ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_KNN(data, labels):\n",
    "    global best_score, best_estimator\n",
    "    temp_score, temp_estimator = KNN_Classify(data, labels, 5)\n",
    "    print(f\"KNeighborsClassifier best score: {temp_score}\")\n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        best_estimator = temp_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4adac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_RandomForest(data, labels):\n",
    "    global best_score, best_estimator\n",
    "    temp_score, temp_estimator = RandomForest_Classify(data, labels, 5)\n",
    "    print(f\"RandomForestClassifier best score: {temp_score}\")\n",
    "    if temp_score > best_score:\n",
    "        best_score = temp_score\n",
    "        best_estimator = temp_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6351312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(data, labels):\n",
    "    check_GaussianNB(data, labels)\n",
    "    # check_SGD(data, labels)\n",
    "    # check_Logistic(data, labels)\n",
    "    # check_SVM(data, labels)\n",
    "    # check_KNN(data, labels)\n",
    "    # check_RandomForest(data, labels)\n",
    "\n",
    "    print(f\"Best score: {best_score}\")\n",
    "    print(f\"Best estimator: {best_estimator}\")\n",
    "\n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f9630f",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "- Save the model in a joblib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e99147e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    \"\"\"\n",
    "    Save the trained model to a file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        joblib.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243d37fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV with 5 folds...\n",
      "Parameter Grid: {'classifier__var_smoothing': [1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]}\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "\n",
      "--- GridSearchCV Complete ---\n",
      "Best Parameters Found: {'classifier__var_smoothing': 0.1}\n",
      "Best Cross-Validation Score (accuracy): 0.741111\n",
      "-----------------------------\n",
      "GaussianNB best score: 0.7411111111111112\n",
      "Best score: 0.7411111111111112\n",
      "Best estimator: Pipeline(steps=[('classifier', GaussianNB(var_smoothing=0.1))])\n"
     ]
    }
   ],
   "source": [
    "find_best_model(data, labels)\n",
    "save_model(best_estimator, '../../models/c2_Classifier_Sentiment_Model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
